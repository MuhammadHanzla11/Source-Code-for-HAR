import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

class SwinTransformerBlock(nn.Module):
    """
    Swin Transformer block for spatio-temporal feature learning
    """
    
    def __init__(self, dim, num_heads, window_size=7, mlp_ratio=4.0, dropout=0.1):
        super(SwinTransformerBlock, self).__init__()
        
        self.dim = dim
        self.num_heads = num_heads
        self.window_size = window_size
        
        # Window-based multi-head self-attention
        self.attention = nn.MultiheadAttention(
            embed_dim=dim,
            num_heads=num_heads,
            dropout=dropout,
            batch_first=True
        )
        
        self.norm1 = nn.LayerNorm(dim)
        self.norm2 = nn.LayerNorm(dim)
        
        # MLP
        mlp_hidden_dim = int(dim * mlp_ratio)
        self.mlp = nn.Sequential(
            nn.Linear(dim, mlp_hidden_dim),
            nn.GELU(),
            nn.Dropout(dropout),
            nn.Linear(mlp_hidden_dim, dim),
            nn.Dropout(dropout)
        )
        
    def forward(self, x):
        # x shape: (batch_size, seq_len, dim)
        
        # Multi-head attention with residual
        shortcut = x
        x = self.norm1(x)
        attn_out, _ = self.attention(x, x, x)
        x = shortcut + attn_out
        
        # MLP with residual
        shortcut = x
        x = self.norm2(x)
        x = shortcut + self.mlp(x)
        
        return x


class GestureRecognitionSwinTransformer(nn.Module):
    """
    Swin Transformer for gesture recognition from optimized features
    """
    
    def __init__(self, input_dim, num_classes, embed_dim=128, depth=4, 
                 num_heads=8, window_size=7, dropout=0.1):
        super(GestureRecognitionSwinTransformer, self).__init__()
        
        self.input_dim = input_dim
        self.num_classes = num_classes
        self.embed_dim = embed_dim
        
        # Input projection
        self.input_projection = nn.Sequential(
            nn.Linear(input_dim, embed_dim),
            nn.LayerNorm(embed_dim),
            nn.Dropout(dropout)
        )
        
        # Positional encoding
        self.pos_embed = nn.Parameter(torch.randn(1, 1000, embed_dim) * 0.02)
        
        # Swin Transformer blocks
        self.blocks = nn.ModuleList([
            SwinTransformerBlock(
                dim=embed_dim,
                num_heads=num_heads,
                window_size=window_size,
                dropout=dropout
            ) for _ in range(depth)
        ])
        
        # Classification head
        self.norm = nn.LayerNorm(embed_dim)
        self.classifier = nn.Sequential(
            nn.Linear(embed_dim, embed_dim // 2),
            nn.GELU(),
            nn.Dropout(dropout),
            nn.Linear(embed_dim // 2, num_classes)
        )
        
    def forward(self, x):
        # x shape: (batch_size, seq_len, input_dim) or (batch_size, input_dim)
        
        # Handle single-frame input
        if len(x.shape) == 2:
            x = x.unsqueeze(1)  # (batch_size, 1, input_dim)
        
        batch_size, seq_len, _ = x.shape
        
        # Project input
        x = self.input_projection(x)  # (batch_size, seq_len, embed_dim)
        
        # Add positional encoding
        x = x + self.pos_embed[:, :seq_len, :]
        
        # Apply Swin Transformer blocks
        for block in self.blocks:
            x = block(x)
        
        # Global average pooling
        x = x.mean(dim=1)  # (batch_size, embed_dim)
        
        # Normalize
        x = self.norm(x)
        
        # Classification
        logits = self.classifier(x)  # (batch_size, num_classes)
        
        return logits


class GestureDataset(Dataset):
    """
    PyTorch Dataset for gesture recognition
    """
    
    def __init__(self, features, labels):
        """
        Args:
            features: Optimized feature array (n_samples, n_features)
            labels: Gesture labels (n_samples,)
        """
        self.features = torch.FloatTensor(features)
        self.labels = torch.LongTensor(labels)
        
    def __len__(self):
        return len(self.labels)
    
    def __getitem__(self, idx):
        return self.features[idx], self.labels[idx]


class GestureClassifier:
    """
    Complete gesture classification pipeline using Swin Transformer
    """
    
    def __init__(self, input_dim, num_classes, embed_dim=128, depth=4, 
                 num_heads=8, learning_rate=0.001, device='cuda'):
        """
        Initialize gesture classifier
        
        Args:
            input_dim: Input feature dimension
            num_classes: Number of gesture classes
            embed_dim: Embedding dimension
            depth: Number of transformer blocks
            num_heads: Number of attention heads
            learning_rate: Learning rate for optimizer
            device: Device to train on
        """
        self.device = torch.device(device if torch.cuda.is_available() else 'cpu')
        
        # Initialize model
        self.model = GestureRecognitionSwinTransformer(
            input_dim=input_dim,
            num_classes=num_classes,
            embed_dim=embed_dim,
            depth=depth,
            num_heads=num_heads
        ).to(self.device)
        
        # Loss and optimizer
        self.criterion = nn.CrossEntropyLoss()
        self.optimizer = optim.AdamW(
            self.model.parameters(),
            lr=learning_rate,
            weight_decay=0.01
        )
        
        # Learning rate scheduler
        self.scheduler = optim.lr_scheduler.CosineAnnealingLR(
            self.optimizer,
            T_max=50,
            eta_min=1e-6
        )
        
    def train_epoch(self, train_loader):
        """
        Train for one epoch
        """
        self.model.train()
        total_loss = 0
        correct = 0
        total = 0
        
        for features, labels in train_loader:
            features = features.to(self.device)
            labels = labels.to(self.device)
            
            # Forward pass
            self.optimizer.zero_grad()
            outputs = self.model(features)
            loss = self.criterion(outputs, labels)
            
            # Backward pass
            loss.backward()
            self.optimizer.step()
            
            # Statistics
            total_loss += loss.item()
            _, predicted = outputs.max(1)
            total += labels.size(0)
            correct += predicted.eq(labels).sum().item()
        
        avg_loss = total_loss / len(train_loader)
        accuracy = 100.0 * correct / total
        
        return avg_loss, accuracy
    
    def evaluate(self, test_loader):
        """
        Evaluate model on test set
        """
        self.model.eval()
        total_loss = 0
        correct = 0
        total = 0
        
        all_predictions = []
        all_labels = []
        
        with torch.no_grad():
            for features, labels in test_loader:
                features = features.to(self.device)
                labels = labels.to(self.device)
                
                outputs = self.model(features)
                loss = self.criterion(outputs, labels)
                
                total_loss += loss.item()
                _, predicted = outputs.max(1)
                total += labels.size(0)
                correct += predicted.eq(labels).sum().item()
                
                all_predictions.extend(predicted.cpu().numpy())
                all_labels.extend(labels.cpu().numpy())
        
        avg_loss = total_loss / len(test_loader)
        accuracy = 100.0 * correct / total
        
        return avg_loss, accuracy, all_predictions, all_labels
    
    def train(self, X_train, y_train, X_val, y_val, epochs=50, batch_size=32):
        """
        Complete training pipeline
        
        Args:
            X_train: Training features
            y_train: Training labels
            X_val: Validation features
            y_val: Validation labels
            epochs: Number of training epochs
            batch_size: Batch size
            
        Returns:
            Training history
        """
        # Create datasets and dataloaders
        train_dataset = GestureDataset(X_train, y_train)
        val_dataset = GestureDataset(X_val, y_val)
        
        train_loader = DataLoader(
            train_dataset,
            batch_size=batch_size,
            shuffle=True,
            num_workers=2
        )
        
        val_loader = DataLoader(
            val_dataset,
            batch_size=batch_size,
            shuffle=False,
            num_workers=2
        )
        
        # Training history
        history = {
            'train_loss': [],
            'train_acc': [],
            'val_loss': [],
            'val_acc': []
        }
        
        best_val_acc = 0.0
        
        print("Starting training...")
        print(f"Device: {self.device}")
        print(f"Train samples: {len(X_train)}, Val samples: {len(X_val)}")
        
        for epoch in range(epochs):
            # Train
            train_loss, train_acc = self.train_epoch(train_loader)
            
            # Validate
            val_loss, val_acc, _, _ = self.evaluate(val_loader)
            
            # Update scheduler
            self.scheduler.step()
            
            # Save history
            history['train_loss'].append(train_loss)
            history['train_acc'].append(train_acc)
            history['val_loss'].append(val_loss)
            history['val_acc'].append(val_acc)
            
            # Save best model
            if val_acc > best_val_acc:
                best_val_acc = val_acc
                self.save_model('best_gesture_model.pth')
            
            # Print progress
            if (epoch + 1) % 5 == 0:
                print(f"Epoch [{epoch+1}/{epochs}]")
                print(f"  Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%")
                print(f"  Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%")
        
        print(f"\nTraining complete. Best validation accuracy: {best_val_acc:.2f}%")
        
        return history
    
    def predict(self, X):
        """
        Predict gesture classes for input features
        
        Args:
            X: Input features (n_samples, n_features)
            
        Returns:
            Predicted class indices
        """
        self.model.eval()
        
        X_tensor = torch.FloatTensor(X).to(self.device)
        
        with torch.no_grad():
            outputs = self.model(X_tensor)
            _, predictions = outputs.max(1)
        
        return predictions.cpu().numpy()
    
    def save_model(self, filepath):
        """
        Save model weights
        """
        torch.save(self.model.state_dict(), filepath)
    
    def load_model(self, filepath):
        """
        Load model weights
        """
        self.model.load_state_dict(torch.load(filepath, map_location=self.device))


# Example usage
if __name__ == "__main__":
    # Load optimized features from LDA module
    X_optimized = np.random.rand(100, 50)  # 100 samples, 50 features
    y = np.random.randint(0, 10, 100)  # 10 gesture classes
    
    # Split data
    X_train, X_val, y_train, y_val = train_test_split(
        X_optimized, y, test_size=0.2, random_state=42, stratify=y
    )
    
    # Initialize classifier
    classifier = GestureClassifier(
        input_dim=50,
        num_classes=10,
        embed_dim=128,
        depth=4,
        num_heads=8,
        learning_rate=0.001,
        device='cuda'
    )
    
    # Train model
    history = classifier.train(
        X_train, y_train,
        X_val, y_val,
        epochs=50,
        batch_size=32
    )
    
    # Predict on validation set
    predictions = classifier.predict(X_val)
    accuracy = accuracy_score(y_val, predictions)
    
    print(f"\nFinal validation accuracy: {accuracy * 100:.2f}%")
    print("\nClassification Report:")
    print(classification_report(y_val, predictions))